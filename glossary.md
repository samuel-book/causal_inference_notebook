# Glossary

* **Average treatment effect**: the difference in mean outcomes between treated and untreated patients across a population (often a population of patients who are considered eligible for treatment). In outcome models the *counterfactual* outcomes for each patient for when they do or or do not receive treatment may be predicted (and averaged across the population). In clinical trails it is the average difference between treated and untreated outcomes (see also *intention-to-treat* and *per-protocol analysis*).

* **Bias**: Bias in causal inference refers to systematic deviations between observed relationships and true causal effects. There are three main types of bias that affect causal studies: 1) *Confounding bias* (or *omitted variable bias*) occurs when a variable, that is either not measured or not controlled for properly, affects both the treatment and outcome but is not included in the analysis, 2) *Selection bias* occurs when there is selection of people into a trial, or selection of people out of results collection for a trial, 3) *Measurement bias* stems from incorrect measurement of outcomes, exposures, or confounding variables.

* **Causal inference**: Causal inference is the process of figuring out whether one thing truly causes another thing to happen. It goes beyond simply noticing that two things are related (correlation) and tries to determine if changing one thing directly leads to changes in another.

* **Collider**: A collider is a variable that gets affected by two or more other variables - imagine it like a point where multiple influences "collide" into each other. Unlike confounders, which need to be controlled for in studies, controlling for a collider can actually create false relationships between variables and mess up your analysis. As an example, consider a sack filled with potatoes and carrots. The total weight of any sack of any size (the collider) is independently affected by both the number of potatoes and the number of carrots. If you look at sacks of the same weight, you'll find that more potatoes means fewer carrots, and vice versa - creating an artificial relationship between two otherwise unrelated variables. The key insight is that these relationships only appear when we focus on (or "condition on") the collider.

* **Conditional average treatment effect (CATE)**: The Conditional Average Treatment Effect (CATE) is the average impact of a treatment or intervention on a specific subgroup of people who share similar characteristics (such as age, race, or sex). Unlike looking at how a treatment affects everyone as a whole, CATE focuses on how it affects particular groups differently.

* **Confounder**: A confounder is a variable that affects both what you're testing (like a treatment) and what you're measuring (like an outcome), which can make it look like there's a relationship between them when there might not be one. Think of it like trying to figure out if yellow finger nails cause lung cancer - they are both caused by smoking, so appear related, but it is the smoking causing both (and so smoking needs to be measured and accounted for in order to avoid concluding that yellow finger nails cause lung cancer).

* **Counterfactual**: The hypothetical outcome that would have occurred under a different treatment condition.

* **Directed Acyclic Graph (DAG)**: A directed acyclic graph (DAG) is a visual tool that maps out cause-and-effect relationships between variables. It uses arrows to show how one variable influences another, with the arrows always pointing in one direction and never creating loops. Think of it as a roadmap showing how different factors affect each other - like how education might affect income, which in turn affects health - but you can never follow the arrows back to where you started (that's the *acyclic* bit). DAGs help researchers identify which variables they need to account for when studying cause-and-effect relationships, and help communicate the presumed causal relationships to others.

* **E-value**: The E-value is a practical tool used in observational studies to assess how strong an unmeasured factor would need to be to invalidate a research finding. It helps researchers understand how robust their findings are against potential hidden factors they couldn't measure or control for. A large E-value indicates that very strong unmeasured confounding would be needed to explain away the results, suggesting the findings are more robust. Calculation is simple: For a given risk ratio (RR), the E-value is calculated using a simple formula that produces a number greater than or equal to 1. For example, if a study finds a risk ratio of 1.50, the corresponding E-value would be 2.37, meaning an unmeasured factor would need to have at least a 2.37-fold association with both the exposure and outcome to nullify the observed effect.

* **External validity**: External validity refers to how well the findings of a scientific study can be applied beyond its original context. In simpler terms, it's about whether the cause-and-effect relationships discovered in a study will hold true in other situations. Compare with *internal validity*.

* **G methods**: G methods are a family of statistical techniques used to estimate cause-and-effect relationships in complex situations, particularly when dealing with treatments or exposures that change over time. They are especially valuable when there's a back-and-forth relationship between treatments and factors that influence both the treatment and outcome. Three main approaches make up the g methods family: 1) G formula, 2) Marginal structural models, 3) Structural nested models.

* **Hazard ratio**: A hazard ratio (HR) is a way to compare how quickly an event happens between two groups - typically a treatment group versus a control group. Think of it as measuring who reaches a particular outcome faster. Unlike other statistical measures (e.g. see *risk ratio*) that only look at whether an event happened by the end of a study, hazard ratios specifically consider when these events occur throughout the entire study period. It's like comparing the speed at which events happen between groups, rather than just counting how many events happened in total.

* **Heterogeneous treatment effects**: Heterogeneous treatment effects are where individual patients vary in their response to treatment. Clinical trials tend to estimate an average treatment effect across the whole population, but further analysis may reveal subgroups of patients who have smaller or larger treatment effects.

* **Interaction**: Interaction in causal inference occurs when the joint effect of two exposures on an outcome differs from the sum of their individual effects.

* **Interference**: Interference in causal inference occurs when one subject's treatment or exposure can affect the outcomes of other subjects. This phenomenon commonly arises in settings where social interactions influence outcomes. An example of interference is vaccination, where vaccination of one person affects others' infection risks. Or prioritisation of one patients treatment may affect the amount of time another patient waits for treatment.

* **Intention-to-treat**: Intention-to-treat (ITT) analysis is a fundamental method in randomized controlled trials where all participants are analyzed according to their originally assigned treatment groups, regardless of whether they actually received the intended treatment or not. The outcome may reflect real life treatment effects better than analysing only those known to have taken the treatment, but may under-estimate the inherent efficacy of the treatment. This compares with *per-protocol analysis* which only includes participants who strictly followed the study protocol and completed the treatment as intended. 

* **Internal validity**: Internal validity is how confident we can be that a cause-and-effect relationship in a study is real and not due to other factors. Think of it as answering the question: "Did A actually cause B, or was something else responsible?". Internal validity is confined to making good conclusions in the study group. Compare with *external validity*.

* **Instrumental variable analysis**: A technique for determining causality that depends on identifying a variable that effects exposure (treatment) but does not affect outcomes directly. Consider studying how a drug affects blood pressure. Instead of just comparing drug use and blood pressure directly, you might use "distance to the nearest pharmacy" as an instrumental variable. People living closer to pharmacies are more likely to take the drug, but their distance from a pharmacy doesn't directly affect their blood pressure in any other way.

* **Inverse propensity weighting**: The outcomes of patients are weighted by their propensity to treat, or more accurately by the inverse propensity to treat. For treated individuals the weight is 1 / p; for untreated individuals the weight is 1 / (1 - p). This effectively gives more weight to patients not treated in the usual way (e.g. gives more weight to looking at the outcome of patients who would normally be expected to be treated but did not receive treatment, and vice versa).

* **Mediator**: A variable that lies along the causal pathway between cause and effect, through which the causal effect may pass.

* **Moderator**: A variable that affects the relationship between cause and effect variables.

* **Parametric (and non-parametric)**: Parametric refers to something that is defined or controlled by parameters. In statistical models these parameters usually define a distribution - once that distribution has been defined then further results (such as confidence limits, or statistical difference between two distributions) may be calculated. Non-parametric models (such as machine learning methods such as random forests or neural networks) are not easily reduced to meaningful parameters. Non-parametric models are usually more flexible (coping with interactions between variables, and complex relationships between a variable and the result), but lack the ability to quickly estimate results such as confidence limits and statistical difference.

* **Per-Protocol Analysis**: Analysis of the effect of treatment when it is known the subject has taken the treatment as intended. This compares with *intention-to-treat* which analyses across the whole population where treatment was intended, whether the treatment was actually taken or not. This analysis may provide a better estimation of the inherent treatment efficacy, but over-estimate real world treatment effects.

* **Propensity score**: the probability that an individual receives a treatment or intervention, given a set of observed data about the patient/setting. This allows better comparison of treatment effects when the people more likely to receive treatment are more likely to have a good/bad outcome compared with those that do not receive treatment. It helps to simplify analysis by combining multiple features about patients/setting into a single variable. The propensity score may be used for 1) *matching*, where pairs of treated and untreated people are identified each with similar propensity scores, *weighting*, where a model includes the propensity score in order to adjust outcome by likelihood to treat, and *subclassification*, where analysis can group people with similar propensity scores. See also *inverse propensity weighting*.

* **Risk ratio**: A risk ratio, also known as relative risk, is a number that shows how much more likely one group is to experience a specific health outcome compared to another group. Risk ratios differ from hazard ratios: Risk ratios measure cumulative risk at a fixed endpoint, whereas hazard ratios measure instantaneous risk at any given point during the study period.

* **SHAP values**: SHAP (SHapley Additive exPlanations) values show how individual features (or combinations of features) in a machine learning model contribute to the final model prediction. They may be applied to all machine learning model types.

* **Target trial emulation**: Target trial emulation is a framework that applies the principles of randomized clinical trials (RCTs) to observational data to estimate the causal effects of interventions. The process begins by designing a hypothetical randomized trial (the "target trial") that would ideally answer the research question. This protocol includes: 1) Eligibility criteria, 2) Treatment strategies
Assignment procedures, 3) Follow-up period, 4) Outcome definitions, 5) Statistical analysis plan. 




